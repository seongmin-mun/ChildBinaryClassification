{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.1"},"colab":{"name":"ChildLSTM_Bi_updated.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"cFEpHz9q2TkF"},"source":["# CDSADS_LSTM\n","바뀐 부분<br>\n","criterion = nn.CrossEntropyLoss()<br>\n","n_layers = 2<br>\n","self.i2h = nn.RNN(input_size + hidden_size, hidden_size, n_layers, dropout=0.3)<br>\n","model = RNN(n_class, n_hidden, n_categories)  # 57, 128, 18 문자수, 히든 수, 분류수<br>\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)<br>\n","optimizer.zero_grad()<br>\n","optimizer.step()<br>\n","사전학습모델: https://github.com/monologg/KoCharELECTRA<br>\n","https://www.marktechpost.com/2019/12/18/<br>classifying-the-name-nationality-of-a-person-using-lstm-and-pytorch/<br>"]},{"cell_type":"code","metadata":{"id":"VPmd3h1VZUs8"},"source":["##Parameter setting\n","setEpoch = 10\n","setLearningRate = 0.0001\n","setEpsilon = 1e-8\n","setBatch = 32\n","setMaxLength = 256\n","setSeed = 42\n","labelNumber = 2\n","setTry = 31"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9LAZ1CSc3Bm_","executionInfo":{"status":"ok","timestamp":1657004285254,"user_tz":-540,"elapsed":22849,"user":{"displayName":"Seongmin Mun","userId":"17295717412647902050"}},"outputId":"c858f793-8e12-4b39-a3e2-c5b41739b22c"},"source":["import tensorflow as tf\n","\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')\n","    \n","import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found GPU at: /device:GPU:0\n","There are 1 GPU(s) available.\n","We will use the GPU: Tesla P100-PCIE-16GB\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X3aCo4t22ahB","executionInfo":{"status":"ok","timestamp":1657004530136,"user_tz":-540,"elapsed":16827,"user":{"displayName":"Seongmin Mun","userId":"17295717412647902050"}},"outputId":"f7184d95-ba6b-47b5-e1a9-6438031f8f2f"},"source":["# Mount Google Drive to this Notebook instance.\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"m7AbJWlRzTk9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d0cf0ff5-6670-4355-afc0-71f41f8b16d1","executionInfo":{"status":"ok","timestamp":1657004669804,"user_tz":-540,"elapsed":18854,"user":{"displayName":"Seongmin Mun","userId":"17295717412647902050"}}},"source":["for currentTry in range(30,setTry):\n","  import pandas as pd\n","  import os\n","\n","  fileDir = \"drive/My Drive/NLP/GH/AgentThemeFirst/Data/Binary/trainBi.csv\"\n","  fr = open(fileDir, 'r')\n","  contents = fr.readlines()\n","  fr.close()\n","\n","  train = pd.DataFrame(columns=('Label', 'Sentence'))\n","  i = 0\n","  label = \"\"\n","  sentence = \"\"\n","  for content in contents:\n","      if i == 0:\n","          pass\n","      else:\n","          infos = content.split(\",\")\n","          label = int(infos[2])\n","          sentence = infos[3].replace(\"\\n\", \"\")\n","          train.loc[i] = [label, sentence]\n","      i = i + 1\n","\n","\n","  train['Sentence'] = train['Sentence'].str.replace(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》\\\\n\\t]+', \" \",regex=True)\n","  train['Sentence'] = train['Sentence'].str.replace(r'\\t+', \" \", regex=True)\n","  train['Sentence'] = train['Sentence'].str.replace(r'[\\\\n]+', \" \", regex=True)\n","\n","  # 리뷰 문장 추출\n","  sentences = train['Sentence']\n","\n","  # # 사전학습모델을 사용 안한 경우\n","  # # # word_list = list(set(\"\".join(sentences).split()))\n","  # word_list = list(set(\"\".join(list(sentences))))\n","  # word_dict = {w: i for i, w in enumerate(word_list)}\n","  # number_dict = {i: w for i, w in enumerate(word_list)}\n","  # n_class = len(word_dict)\n","\n","  # CHILDES데이터 사용하여 사전학습 모델 튜닝\n","  entireCorpus = \"drive/My Drive/NLP/GH/AgentThemeFirst/Data/Binary/CHILDES/CHILDES_all_spellchecked_corrected.txt\"\n","  entireFr = open(entireCorpus, 'r')\n","  entireContents = entireFr.readlines()\n","  entireFr.close()\n","\n","  import re\n","\n","  entireSet = set()\n","\n","  #음절을 추가\n","  for entireContent in entireContents:\n","      entireContent = re.sub('[^가-힣]', ' ', entireContent)\n","      entireContent = re.sub('[\\s]+', '', entireContent)\n","      for each in entireContent:\n","          entireSet.add(each)\n","\n","  # print(\"child:\",len(entireSet))\n","\n","  # 사전학습 모델 사용\n","  # 사전학습모델: https://github.com/monologg/KoCharELECTRA\n","  preFileDir = \"drive/My Drive/NLP/GH/AgentThemeFirst/Data/Binary/Pretrained_model/vocab.txt\"\n","  preFr = open(preFileDir, 'r')\n","  preContents = preFr.readlines()\n","  preFr.close()\n","\n","  entireSet2 = set()\n","\n","  for content in preContents:\n","    content = content.replace(\"\\n\",\"\")\n","    if content != \" \":\n","        entireSet.add(content)\n","        entireSet2.add(content)\n","\n","  print(\"pre-trained:\", len(entireSet2))\n","  print(\"child+pre-trained:\",len(entireSet))\n","\n","  word_list = []\n","  for content in entireSet:\n","      word_list.append(content.replace(\"\\n\", \"\"))\n","  word_dict = {w: i for i, w in enumerate(word_list)}\n","  number_dict = {i: w for i, w in enumerate(word_list)}\n","  n_class = len(word_dict)\n","\n","  print(word_list)\n","  print(word_dict)\n","  print(number_dict)\n","  print(n_class)\n","\n","  category_lines = {}\n","  all_categories = []\n","  for i in range(0,2):\n","      category = train['Label'] == i\n","      categoryName = \"pattern\"+str(i)\n","      category_lines[categoryName] = list(train[category]['Sentence'])\n","      all_categories.append(categoryName)\n","\n","  n_categories = len(all_categories)\n","  print(category_lines)\n","  print(all_categories)\n","\n","\n","\n","\n","\n","  import torch\n","\n","  def charToIndex(char):\n","      return ''.join(word_list).find(char)\n","\n","  def charToTensor(char):\n","      tensor = torch.zeros(1, n_class)\n","      tensor[0][charToIndex(char)] = 1\n","      return tensor\n","\n","  def lineToTensor(line):\n","      tensor = torch.zeros(len(line), 1, n_class)\n","      for li, char in enumerate(line):\n","          tensor[li][0][charToIndex(char)] = 1\n","      return tensor\n","\n","  import torch.nn as nn\n","  import torch\n","  torch.set_default_tensor_type('torch.cuda.FloatTensor')\n","\n","  #os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n","  #os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1,2\"\n","\n","  # 인풋-히든-아웃풋 형태의 신경망\n","\n","  class LSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        super(LSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.lstm_cell = nn.LSTM(input_size, hidden_size)  # LSTM cell\n","        self.h2o = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=2)\n","\n","    def forward(self, input, hidden):\n","        out, hidden = self.lstm_cell(input.view(1, 1, -1), hidden)\n","        output = self.h2o(hidden[0])\n","        output = self.softmax(output)\n","        return output.view(1, -1), hidden\n","\n","    def initHidden(self):\n","        return (torch.zeros(1, 1, self.hidden_size), torch.zeros(1, 1, self.hidden_size))\n","\n","  n_hidden = 256 #RNN층의 히든 갯수   36, 64,  128\n","  model = LSTM(n_class, n_hidden, n_categories).to(device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')) # 57, 256, 2 음절 갯수, 히든 수, 분류수\n","  \n","\n","  print(model)\n","\n","  def categoryFromOutput(output):\n","      top_n, top_i = output.topk(1)  # 텐서의 가장 큰 값 및 주소\n","      category_i = top_i[0].item()  # 텐서에서 정수 값으로 변경\n","      return all_categories[category_i], category_i\n","\n","\n","  def trainingExample(cateNum, lineNum):\n","      category = all_categories[cateNum] # 0부터 24\n","      line = category_lines[category][lineNum]\n","      category_tensor = torch.tensor([all_categories.index(category)], dtype=torch.long)\n","      line_tensor = lineToTensor(line)\n","      return category, line, category_tensor, line_tensor\n","\n","  ###############################모델학습 설정########################################\n","  # criterion = nn.NLLLoss()\n","  criterion = nn.CrossEntropyLoss() # change\n","  # learning_rate = 0.002  # 이것을 너무 높게 설정하면 발산할 수 있고, 너무 낮으면 학습이 되지 않을 수 있습니다.\n","  learning_rate = setLearningRate   # 0.0001 , 0.005, 0.001\n","  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","  def train(category_tensor, line_tensor):\n","      hidden = model.initHidden()\n","\n","      optimizer.zero_grad()\n","      for i in range(line_tensor.size()[0]):\n","          output, hidden = model(line_tensor[i], hidden)\n","\n","      loss = criterion(output, category_tensor)\n","      loss.backward()\n","      optimizer.step()\n","\n","      # 매개변수의 경사도에 학습률을 곱해서 그 매개변수의 값에 더합니다.\n","      # for p in rnn.parameters():\n","      #     p.data.add_(p.grad.data, alpha=-learning_rate)\n","\n","      return output, loss.item(), hidden\n","\n","\n","  ##############################결과구문으로출력###################################\n","  def outreault(guess):\n","      guess = int(guess)\n","      outConstruction = \"\"\n","      if guess == 0:\n","          outConstruction = \"agent-first\"\n","      elif guess == 1:\n","          outConstruction = \"theme-first\"\n","\n","      return outConstruction\n","\n","\n","  ###############################모델학습########################################\n","  import time\n","  import math\n","\n","  n_iters = setEpoch\n","  print_every = 10000\n","  plot_every = 500\n","\n","  # 도식화를 위한 손실 추적\n","  current_loss = 0\n","  all_losses = []\n","\n","  def timeSince(since):\n","      now = time.time()\n","      s = now - since\n","      m = math.floor(s / 60)\n","      s -= m * 60\n","      return '%dm %ds' % (m, s)\n","\n","  start = time.time()\n","\n","  eachClassLength = []\n","  for cateNum in range(0, len(all_categories)):\n","      currentCategory = all_categories[cateNum]\n","      eachClassLength.append(len(category_lines[currentCategory]))\n","\n","  maxLength = max(eachClassLength) #-> 9패턴 1938\n","\n","  outDir = \"drive/My Drive/NLP/GH/AgentThemeFirst/Data/Binary/OutputLSTM/lstmBi_All_T\"+ str(currentTry) +\".csv\"\n","  f = open(outDir, 'w')\n","\n","  f.write(\"epoch,sentence,originalLabel,predictedLabel,predictedConstruction,result\"+\"\\n\")\n","\n","\n","  learningNum = 0\n","  for iter in range(1, n_iters + 1):\n","\n","      maxLengthList = []\n","      for i in range(0, maxLength):\n","          maxLengthList.append(i)\n","\n","      import random\n","      for i in range(0, maxLength):\n","          index = random.randint(0, len(maxLengthList) - 1)\n","          selectedID = maxLengthList[index]\n","\n","          categoryNumList = []\n","          for cateNum in range(0, len(all_categories)):\n","              categoryNumList.append(cateNum)\n","\n","          for j in range(0, n_categories):\n","              id = random.randint(0, len(categoryNumList) - 1)\n","              selectedIndex = categoryNumList[id]\n","\n","              currentCategory = all_categories[selectedIndex]\n","\n","              try:\n","                  category, line, category_tensor, line_tensor = trainingExample(selectedIndex, selectedID)\n","                  # print(category, line, category_tensor, line_tensor, learningNum)\n","                  output, loss, hidden = train(category_tensor, line_tensor)  # 각 학습단계의 정보가 담긴 hidden\n","                  current_loss += loss\n","\n","                  learningNum = learningNum + 1\n","\n","                  # iter 숫자, 손실, 이름, 추측 화면 출력\n","                  if learningNum % print_every == 0:\n","                      guess, guess_i = categoryFromOutput(output)\n","                      correct = '✓' if guess == category else '✗ (%s)' % category\n","                      print('%d %d%% (%s) %.4f %s / %s %s' % (\n","                          iter, iter / n_iters * 100, timeSince(start), loss, line, guess, correct))\n","\n","                  # 현재 평균 손실을 전체 손실 리스트에 추가\n","                  if learningNum % plot_every == 0:\n","                      all_losses.append(current_loss / plot_every)\n","                      current_loss = 0\n","              except IndexError:\n","                  pass\n","\n","              categoryNumList.remove(selectedIndex)\n","\n","          maxLengthList.remove(selectedID)\n","\n","      if iter == 1 or iter == 2 or iter == 3 or iter == 4 or iter == 5 or iter == 6 or iter == 7 or iter == 8 or iter == 9 or iter == 10:# or iter == 20 or iter == 30:# or iter == 40 or iter == 50:\n","          # ###############################전체 모델 성능 평가########################################\n","\n","          print(\"-----\" + str(iter) + \" learning result-----\")\n","\n","          def evaluate(line_tensor):\n","              hidden = model.initHidden()\n","\n","              for i in range(line_tensor.size()[0]):\n","                  output, hidden = model(line_tensor[i], hidden)\n","\n","              return output\n","\n","          def predict(input_line):\n","              # print('\\n> %s' % input_line)\n","              with torch.no_grad():\n","                  output = evaluate(lineToTensor(input_line))\n","                  guess, guess_i = categoryFromOutput(output)\n","\n","              return input_line, guess\n","\n","          import pandas as pd\n","\n","          testFileDir = \"drive/My Drive/NLP/GH/AgentThemeFirst/Data/Binary/testBi_All.csv\"\n","          testFr = open(testFileDir, 'r')\n","          testContents = testFr.readlines()\n","          testFr.close()\n","\n","          test = pd.DataFrame(columns=('Label1', 'Label2', 'Sentence'))\n","          i = 0\n","          for content in testContents:\n","              if i == 0:\n","                  pass\n","              else:\n","                  infos = content.split(\",\")\n","                  label1 = int(infos[0])\n","                  label2 = int(infos[1])\n","                  sentence = infos[2].replace(\"\\n\", \"\")\n","                  test.loc[i] = [label1, label2, sentence]\n","              i = i + 1\n","\n","          test['Sentence'] = test['Sentence'].str.replace(r'[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》\\\\n\\t]+',\n","                                                          \" \", regex=True)\n","          test['Sentence'] = test['Sentence'].str.replace(r'\\t+', \" \", regex=True)\n","          test['Sentence'] = test['Sentence'].str.replace(r'[\\\\n]+', \" \", regex=True)\n","\n","          # 리뷰 문장 추출\n","          testSentences = test['Sentence']\n","\n","          totalNum = 0\n","          correctNum = 0\n","          for each in range(0, len(testSentences)):\n","              print(test['Label1'][each + 1], test['Label2'][each + 1], test['Sentence'][each + 1])\n","              sentence, guess = predict(test['Sentence'][each + 1])\n","              guess = guess.replace(\"pattern\", \"\")\n","              if guess == str(test['Label1'][each + 1]) or guess == str(test['Label2'][each + 1]):\n","                  print(\"input: \", sentence, \", predict: \", guess, \"(O)\")\n","                  f.write(str(iter) + \",\" + sentence + \",\" + str(test['Label1'][each + 1]) + \"or\" + str(test['Label2'][each + 1]) + \",\" + guess + \",\" + outreault(guess)+ \",1\" + \"\\n\")\n","                  correctNum = correctNum + 1\n","              else:\n","                  f.write(str(iter) + \",\" + sentence + \",\" + str(test['Label1'][each + 1]) + \"or\" + str(test['Label2'][each + 1]) + \",\" + guess + \",\" + outreault(guess) + \",0\" + \"\\n\")\n","                  print(\"input: \", sentence, \", predict: \", guess, \"(X)\")\n","              totalNum = totalNum + 1\n","\n","          print(\"totalNum: \", totalNum, \" correctNum: \", correctNum, \" accuracy: \", (correctNum / totalNum))\n","\n","  f.close()\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["child: 1490\n","pre-trained: 11360\n","child+pre-trained: 11360\n"]}]}]}